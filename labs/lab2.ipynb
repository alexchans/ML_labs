{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58735e70",
   "metadata": {},
   "source": [
    "## GROUP MEMBERS\n",
    "- **Alex Chen** \n",
    "- **Paige Maple** \n",
    "- **Sam Valentine**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1ffce",
   "metadata": {},
   "source": [
    "### Sources\n",
    "1. https://github.com/eclarson/MachineLearningNotebooks/blob/master/04.%20Dimension%20Reduction%20and%20Images.ipynb\n",
    "2. ChatGPT (For formatting text and plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8fd5b",
   "metadata": {},
   "source": [
    "### Business Understanding (2 pts)\n",
    "\n",
    "1. **Overview of the Dataset and Its Purpose**  \n",
    "   The **Pistachio Image Dataset** ([Kaggle link](https://www.kaggle.com/datasets/muratkokludataset/pistachio-image-dataset)) is a carefully curated collection of images featuring two distinct pistachio varieties: **Kirmizi** and **Siirt**. These varieties differ in both **appearance and nutritional profile**. Kirmizi pistachios are known for their **vibrant color and bold flavor**, while Siirt pistachios are valued for their **smoother taste and slightly different protein content**. For example, Acar and Eti (2011) report protein ranges of **18.23–19.09% for Kirmizi** and **17.51–18.08% for Siirt**, highlighting subtle but meaningful nutritional differences.  \n",
    "   The purpose of the dataset is twofold: (1) to enable the development of an advanced **image classification model** that can automatically distinguish between these varieties, and (2) to support both **processors** and **consumers** in the pistachio industry. Processors benefit from automated sorting and precise labeling, which enhances efficiency and product credibility. Consumers, on the other hand, gain confidence in identifying the pistachio variety that best suits their dietary needs or flavor preferences.  \n",
    "\n",
    "2. **Prediction Task**  \n",
    "   For our project, the **prediction task** is to build an **image classification model** that can accurately differentiate between **Kirmizi** and **Siirt pistachios**. Unlike regression-based tasks, this is a **binary classification problem**, where each pistachio image is assigned to one of the two categories. The state-of-the-art accuracy for this dataset currently stands at **99.89%**, and our objective is to **meet or exceed this benchmark**. Achieving such high precision is critical because even small misclassifications could reduce trust in the model for commercial use, especially in automated processing pipelines.  \n",
    "\n",
    "3. **Why This Matters and Performance Expectations**  \n",
    "   The results of this classification task are meaningful for **multiple stakeholders**. For **processors**, high accuracy ensures consistent quality control and reduces human error in sorting. For **consumers**, particularly those with dietary goals (e.g., athletes monitoring protein intake), the ability to reliably identify pistachio varieties supports **informed food choices**. Beyond these practical applications, this project also showcases the potential of **machine learning in agriculture**, where advanced models can streamline product handling and improve consumer knowledge.  \n",
    "   By aiming for **above 99.89% accuracy**, we push the boundaries of agricultural image classification, striving to deliver a model that is both **reliable and industry-competitive**. In doing so, the Pistachio Image Dataset becomes more than just a collection of images—it becomes a **gateway to smarter agricultural practices and better consumer transparency**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e98ec4",
   "metadata": {},
   "source": [
    "### Data Preparation (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f730dcc",
   "metadata": {},
   "source": [
    "#### Part One (0.5 pts)\n",
    "Read in your images as numpy arrays. Resize and recolor images as necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457d857",
   "metadata": {},
   "source": [
    "#### Part Two (0.4 pts)\n",
    "Linearize the images to create a table of 1-D image features (each row should be one image).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f8ec9",
   "metadata": {},
   "source": [
    "#### Part Three (0.1 pts)\n",
    "Visualize several images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3db85",
   "metadata": {},
   "source": [
    "### Data Reduction (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63d0f8",
   "metadata": {},
   "source": [
    "#### Part One (0.5 pts)\n",
    "Perform linear dimensionality reduction of the images using principal components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9388d",
   "metadata": {},
   "source": [
    "#### Part Two (0.5 pts)\n",
    "Perform linear dimensionality reduction of your image data using randomized principle components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f49cf",
   "metadata": {},
   "source": [
    "#### Part Three (2 pts)\n",
    "Compare the representation using PCA and Randomized PCA. The method you choose to compare dimensionality methods should quantitatively explain which method is better at representing the images with fewer components.  Do you prefer one method over another? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deec220",
   "metadata": {},
   "source": [
    "#### Part Four (1 pts)\n",
    "Perform feature extraction upon the images using any feature extraction technique (e.g., gabor filters, ordered gradients, DAISY, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815dd48d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Part Five (2 pts)\n",
    "Does this feature extraction method show promise for your prediction task? Why? Use visualizations to analyze this questions. For example, visualize the differences between statistics of extracted features in each target class. Another option, use a heat map of the pairwise differences (ordered by class) among all extracted features. Another option, build a nearest neighbor classifier to see actual classification performance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7aa124",
   "metadata": {},
   "source": [
    "### Exceptional Work (1 pts)\n",
    "Perform feature extraction upon the images using DAISY. Rather than using matching on the images with the total DAISY vector, you will instead use key point matching. You will need to investigate appropriate methods for key point matching using DAISY. NOTE: this often requires some type of brute force matching per pair of images, which can be computationally expensive. Does it perform better than not using key point matching? "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
